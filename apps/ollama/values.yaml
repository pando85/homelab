ollama:
  ollama:
    gpu:
      enabled: true
      type: 'nvidia'
    models:
      pull:
        - qwen2.5:3b
      run: []

  extraEnv:
    - name: NVIDIA_VISIBLE_DEVICES
      value: all
    - name: TZ
      value: Europe/Madrid
    - name: OLLAMA_DEBUG
      value: "0"
  ingress:
    enabled: true
    className: nginx-internal
    annotations:
      external-dns.alpha.kubernetes.io/enabled: "true"
      cert-manager.io/cluster-issuer: letsencrypt-prod-dns
    hosts:
      - host: &host ollama.internal.grigri.cloud
        paths:
          - path: /
            pathType: Prefix
    tls:
      - hosts:
          - *host
        secretName: ollama-tls-certificate

  resources:
    requests:
      cpu: 200m
      memory: 5Gi
    limits:
      memory: 12Gi

  runtimeClassName: nvidia

  podLabels:
    pod-cleaner.dbcloud.org/watch: "true"
  podSecurityContext:
    allowPrivilegeEscalation: false
    readOnlyRootFilesystem: true
    capabilities:
      drop:
        - ALL
  securityContext:
    runAsNonRoot: false
    fsGroupChangePolicy: OnRootMismatch
    seccompProfile:
      type: RuntimeDefault
  volumes:
    - emptyDir: {}
      name: ollama-temp
  volumeMounts:
    - mountPath: /.ollama
      name: ollama-temp
  persistentVolume:
    enabled: true
    existingClaim: ollama-data
