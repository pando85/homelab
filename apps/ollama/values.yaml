ollama:
  ollama:
    gpu:
      enabled: true
      type: 'nvidia'
    models:
      pull: []
        # - qwen2.5:3b
      run: []

  extraEnv:
    - name: NVIDIA_VISIBLE_DEVICES
      value: all
    - name: TZ
      value: Europe/Madrid
    - name: OLLAMA_DEBUG
      value: "0"
  ingress:
    enabled: true
    className: nginx-internal
    annotations:
      external-dns.alpha.kubernetes.io/enabled: "true"
      cert-manager.io/cluster-issuer: letsencrypt-prod-dns
    hosts:
      - host: &host ollama.internal.grigri.cloud
        paths:
          - path: /
            pathType: Prefix
    tls:
      - hosts:
          - *host
        secretName: ollama-tls-certificate

  resources:
    requests:
      cpu: 10m
      memory: 20Mi
    limits:
      memory: 2Gi
      nvidia.com/gpu: 1

  runtimeClassName: nvidia

  podLabels:
    pod-cleaner.dbcloud.org/watch: "true"
  podSecurityContext:
    fsGroup: 10001
    runAsGroup: 10001
    runAsNonRoot: true
    runAsUser: 10001
    fsGroupChangePolicy: "OnRootMismatch"
  securityContext:
    runAsNonRoot: false
    seccompProfile:
      type: RuntimeDefault
  volumes:
    - emptyDir: {}
      name: ollama-temp
  volumeMounts:
    - mountPath: /.ollama
      name: ollama-temp
  persistentVolume:
    enabled: true
    existingClaim: ollama-data
